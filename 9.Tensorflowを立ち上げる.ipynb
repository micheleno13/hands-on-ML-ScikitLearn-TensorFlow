{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最初のグラフの生成とセッション内での実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "sess.close()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init.run()\n",
    "result = f.eval()\n",
    "sess.close()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グラフの管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    print(x2.graph is tf.get_default_graph())\n",
    "\n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ノードの値のライフサイクル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlowによる線形回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   8.3252       41.            6.98412698 ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   8.3014       21.            6.23813708 ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   7.2574       52.            8.28813559 ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.7          17.            5.20554273 ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.8672       18.            5.32951289 ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   2.3886       16.            5.25471698 ...    2.61698113\n",
      "    39.37       -121.24      ]]\n",
      "[[   1.            8.3252       41.         ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   1.            8.3014       21.         ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   1.            7.2574       52.         ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.            1.7          17.         ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.            1.8672       18.         ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   1.            2.3886       16.         ...    2.61698113\n",
      "    39.37       -121.24      ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "print(housing.data)\n",
    "print(housing_data_plus_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.526 3.585 3.521 ... 0.923 0.847 0.894]\n",
      "[[4.526]\n",
      " [3.585]\n",
      " [3.521]\n",
      " ...\n",
      " [0.923]\n",
      " [0.847]\n",
      " [0.894]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "print(housing.target)\n",
    "print(housing.target.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7465141e+01],\n",
       "       [ 4.3573415e-01],\n",
       "       [ 9.3382923e-03],\n",
       "       [-1.0662201e-01],\n",
       "       [ 6.4410698e-01],\n",
       "       [-4.2513184e-06],\n",
       "       [-3.7732250e-03],\n",
       "       [-4.2664889e-01],\n",
       "       [-4.4051403e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "\n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 勾配降下法の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マニュアルの勾配計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 11.325348\n",
      "Epoch 100 MSE = 4.9488482\n",
      "Epoch 200 MSE = 4.888695\n",
      "Epoch 300 MSE = 4.8650312\n",
      "Epoch 400 MSE = 4.848227\n",
      "Epoch 500 MSE = 4.836048\n",
      "Epoch 600 MSE = 4.827201\n",
      "Epoch 700 MSE = 4.8207726\n",
      "Epoch 800 MSE = 4.816094\n",
      "Epoch 900 MSE = 4.812681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_housing_data_plus_bias = scaler.fit_transform(housing_data_plus_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自動微分を使った方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 7.3161187\n",
      "Epoch 100 MSE = 5.007195\n",
      "Epoch 200 MSE = 4.9328346\n",
      "Epoch 300 MSE = 4.896245\n",
      "Epoch 400 MSE = 4.8703127\n",
      "Epoch 500 MSE = 4.8516293\n",
      "Epoch 600 MSE = 4.8381634\n",
      "Epoch 700 MSE = 4.8284397\n",
      "Epoch 800 MSE = 4.821425\n",
      "Epoch 900 MSE = 4.8163614\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オプティマイザを使うと"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 10.164854\n",
      "Epoch 100 MSE = 5.1071\n",
      "Epoch 200 MSE = 5.0046377\n",
      "Epoch 300 MSE = 4.9482555\n",
      "Epoch 400 MSE = 4.907886\n",
      "Epoch 500 MSE = 4.878766\n",
      "Epoch 600 MSE = 4.857755\n",
      "Epoch 700 MSE = 4.8425956\n",
      "Epoch 800 MSE = 4.831656\n",
      "Epoch 900 MSE = 4.823761\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 7.6721983\n",
      "Epoch 100 MSE = 4.8059125\n",
      "Epoch 200 MSE = 4.8033953\n",
      "Epoch 300 MSE = 4.803269\n",
      "Epoch 400 MSE = 4.803256\n",
      "Epoch 500 MSE = 4.8032565\n",
      "Epoch 600 MSE = 4.8032537\n",
      "Epoch 700 MSE = 4.803252\n",
      "Epoch 800 MSE = 4.803252\n",
      "Epoch 900 MSE = 4.803251\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練アルゴリズムへのデータの供給"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  9. 14.]]\n",
      "[[21. 30. 41.]\n",
      " [54. 69. 86.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "    \n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0\n",
      "Epoch= 1\n",
      "Epoch= 2\n",
      "Epoch= 3\n",
      "Epoch= 4\n",
      "Epoch= 5\n",
      "Epoch= 6\n",
      "Epoch= 7\n",
      "Epoch= 8\n",
      "Epoch= 9\n",
      "Epoch= 10\n",
      "Epoch= 11\n",
      "Epoch= 12\n",
      "Epoch= 13\n",
      "Epoch= 14\n",
      "Epoch= 15\n",
      "Epoch= 16\n",
      "Epoch= 17\n",
      "Epoch= 18\n",
      "Epoch= 19\n",
      "Epoch= 20\n",
      "Epoch= 21\n",
      "Epoch= 22\n",
      "Epoch= 23\n",
      "Epoch= 24\n",
      "Epoch= 25\n",
      "Epoch= 26\n",
      "Epoch= 27\n",
      "Epoch= 28\n",
      "Epoch= 29\n",
      "Epoch= 30\n",
      "Epoch= 31\n",
      "Epoch= 32\n",
      "Epoch= 33\n",
      "Epoch= 34\n",
      "Epoch= 35\n",
      "Epoch= 36\n",
      "Epoch= 37\n",
      "Epoch= 38\n",
      "Epoch= 39\n",
      "Epoch= 40\n",
      "Epoch= 41\n",
      "Epoch= 42\n",
      "Epoch= 43\n",
      "Epoch= 44\n",
      "Epoch= 45\n",
      "Epoch= 46\n",
      "Epoch= 47\n",
      "Epoch= 48\n",
      "Epoch= 49\n",
      "Epoch= 50\n",
      "Epoch= 51\n",
      "Epoch= 52\n",
      "Epoch= 53\n",
      "Epoch= 54\n",
      "Epoch= 55\n",
      "Epoch= 56\n",
      "Epoch= 57\n",
      "Epoch= 58\n",
      "Epoch= 59\n",
      "Epoch= 60\n",
      "Epoch= 61\n",
      "Epoch= 62\n",
      "Epoch= 63\n",
      "Epoch= 64\n",
      "Epoch= 65\n",
      "Epoch= 66\n",
      "Epoch= 67\n",
      "Epoch= 68\n",
      "Epoch= 69\n",
      "Epoch= 70\n",
      "Epoch= 71\n",
      "Epoch= 72\n",
      "Epoch= 73\n",
      "Epoch= 74\n",
      "Epoch= 75\n",
      "Epoch= 76\n",
      "Epoch= 77\n",
      "Epoch= 78\n",
      "Epoch= 79\n",
      "Epoch= 80\n",
      "Epoch= 81\n",
      "Epoch= 82\n",
      "Epoch= 83\n",
      "Epoch= 84\n",
      "Epoch= 85\n",
      "Epoch= 86\n",
      "Epoch= 87\n",
      "Epoch= 88\n",
      "Epoch= 89\n",
      "Epoch= 90\n",
      "Epoch= 91\n",
      "Epoch= 92\n",
      "Epoch= 93\n",
      "Epoch= 94\n",
      "Epoch= 95\n",
      "Epoch= 96\n",
      "Epoch= 97\n",
      "Epoch= 98\n",
      "Epoch= 99\n",
      "Epoch= 100\n",
      "Epoch= 101\n",
      "Epoch= 102\n",
      "Epoch= 103\n",
      "Epoch= 104\n",
      "Epoch= 105\n",
      "Epoch= 106\n",
      "Epoch= 107\n",
      "Epoch= 108\n",
      "Epoch= 109\n",
      "Epoch= 110\n",
      "Epoch= 111\n",
      "Epoch= 112\n",
      "Epoch= 113\n",
      "Epoch= 114\n",
      "Epoch= 115\n",
      "Epoch= 116\n",
      "Epoch= 117\n",
      "Epoch= 118\n",
      "Epoch= 119\n",
      "Epoch= 120\n",
      "Epoch= 121\n",
      "Epoch= 122\n",
      "Epoch= 123\n",
      "Epoch= 124\n",
      "Epoch= 125\n",
      "Epoch= 126\n",
      "Epoch= 127\n",
      "Epoch= 128\n",
      "Epoch= 129\n",
      "Epoch= 130\n",
      "Epoch= 131\n",
      "Epoch= 132\n",
      "Epoch= 133\n",
      "Epoch= 134\n",
      "Epoch= 135\n",
      "Epoch= 136\n",
      "Epoch= 137\n",
      "Epoch= 138\n",
      "Epoch= 139\n",
      "Epoch= 140\n",
      "Epoch= 141\n",
      "Epoch= 142\n",
      "Epoch= 143\n",
      "Epoch= 144\n",
      "Epoch= 145\n",
      "Epoch= 146\n",
      "Epoch= 147\n",
      "Epoch= 148\n",
      "Epoch= 149\n",
      "Epoch= 150\n",
      "Epoch= 151\n",
      "Epoch= 152\n",
      "Epoch= 153\n",
      "Epoch= 154\n",
      "Epoch= 155\n",
      "Epoch= 156\n",
      "Epoch= 157\n",
      "Epoch= 158\n",
      "Epoch= 159\n",
      "Epoch= 160\n",
      "Epoch= 161\n",
      "Epoch= 162\n",
      "Epoch= 163\n",
      "Epoch= 164\n",
      "Epoch= 165\n",
      "Epoch= 166\n",
      "Epoch= 167\n",
      "Epoch= 168\n",
      "Epoch= 169\n",
      "Epoch= 170\n",
      "Epoch= 171\n",
      "Epoch= 172\n",
      "Epoch= 173\n",
      "Epoch= 174\n",
      "Epoch= 175\n",
      "Epoch= 176\n",
      "Epoch= 177\n",
      "Epoch= 178\n",
      "Epoch= 179\n",
      "Epoch= 180\n",
      "Epoch= 181\n",
      "Epoch= 182\n",
      "Epoch= 183\n",
      "Epoch= 184\n",
      "Epoch= 185\n",
      "Epoch= 186\n",
      "Epoch= 187\n",
      "Epoch= 188\n",
      "Epoch= 189\n",
      "Epoch= 190\n",
      "Epoch= 191\n",
      "Epoch= 192\n",
      "Epoch= 193\n",
      "Epoch= 194\n",
      "Epoch= 195\n",
      "Epoch= 196\n",
      "Epoch= 197\n",
      "Epoch= 198\n",
      "Epoch= 199\n",
      "Epoch= 200\n",
      "Epoch= 201\n",
      "Epoch= 202\n",
      "Epoch= 203\n",
      "Epoch= 204\n",
      "Epoch= 205\n",
      "Epoch= 206\n",
      "Epoch= 207\n",
      "Epoch= 208\n",
      "Epoch= 209\n",
      "Epoch= 210\n",
      "Epoch= 211\n",
      "Epoch= 212\n",
      "Epoch= 213\n",
      "Epoch= 214\n",
      "Epoch= 215\n",
      "Epoch= 216\n",
      "Epoch= 217\n",
      "Epoch= 218\n",
      "Epoch= 219\n",
      "Epoch= 220\n",
      "Epoch= 221\n",
      "Epoch= 222\n",
      "Epoch= 223\n",
      "Epoch= 224\n",
      "Epoch= 225\n",
      "Epoch= 226\n",
      "Epoch= 227\n",
      "Epoch= 228\n",
      "Epoch= 229\n",
      "Epoch= 230\n",
      "Epoch= 231\n",
      "Epoch= 232\n",
      "Epoch= 233\n",
      "Epoch= 234\n",
      "Epoch= 235\n",
      "Epoch= 236\n",
      "Epoch= 237\n",
      "Epoch= 238\n",
      "Epoch= 239\n",
      "Epoch= 240\n",
      "Epoch= 241\n",
      "Epoch= 242\n",
      "Epoch= 243\n",
      "Epoch= 244\n",
      "Epoch= 245\n",
      "Epoch= 246\n",
      "Epoch= 247\n",
      "Epoch= 248\n",
      "Epoch= 249\n",
      "Epoch= 250\n",
      "Epoch= 251\n",
      "Epoch= 252\n",
      "Epoch= 253\n",
      "Epoch= 254\n",
      "Epoch= 255\n",
      "Epoch= 256\n",
      "Epoch= 257\n",
      "Epoch= 258\n",
      "Epoch= 259\n",
      "Epoch= 260\n",
      "Epoch= 261\n",
      "Epoch= 262\n",
      "Epoch= 263\n",
      "Epoch= 264\n",
      "Epoch= 265\n",
      "Epoch= 266\n",
      "Epoch= 267\n",
      "Epoch= 268\n",
      "Epoch= 269\n",
      "Epoch= 270\n",
      "Epoch= 271\n",
      "Epoch= 272\n",
      "Epoch= 273\n",
      "Epoch= 274\n",
      "Epoch= 275\n",
      "Epoch= 276\n",
      "Epoch= 277\n",
      "Epoch= 278\n",
      "Epoch= 279\n",
      "Epoch= 280\n",
      "Epoch= 281\n",
      "Epoch= 282\n",
      "Epoch= 283\n",
      "Epoch= 284\n",
      "Epoch= 285\n",
      "Epoch= 286\n",
      "Epoch= 287\n",
      "Epoch= 288\n",
      "Epoch= 289\n",
      "Epoch= 290\n",
      "Epoch= 291\n",
      "Epoch= 292\n",
      "Epoch= 293\n",
      "Epoch= 294\n",
      "Epoch= 295\n",
      "Epoch= 296\n",
      "Epoch= 297\n",
      "Epoch= 298\n",
      "Epoch= 299\n",
      "Epoch= 300\n",
      "Epoch= 301\n",
      "Epoch= 302\n",
      "Epoch= 303\n",
      "Epoch= 304\n",
      "Epoch= 305\n",
      "Epoch= 306\n",
      "Epoch= 307\n",
      "Epoch= 308\n",
      "Epoch= 309\n",
      "Epoch= 310\n",
      "Epoch= 311\n",
      "Epoch= 312\n",
      "Epoch= 313\n",
      "Epoch= 314\n",
      "Epoch= 315\n",
      "Epoch= 316\n",
      "Epoch= 317\n",
      "Epoch= 318\n",
      "Epoch= 319\n",
      "Epoch= 320\n",
      "Epoch= 321\n",
      "Epoch= 322\n",
      "Epoch= 323\n",
      "Epoch= 324\n",
      "Epoch= 325\n",
      "Epoch= 326\n",
      "Epoch= 327\n",
      "Epoch= 328\n",
      "Epoch= 329\n",
      "Epoch= 330\n",
      "Epoch= 331\n",
      "Epoch= 332\n",
      "Epoch= 333\n",
      "Epoch= 334\n",
      "Epoch= 335\n",
      "Epoch= 336\n",
      "Epoch= 337\n",
      "Epoch= 338\n",
      "Epoch= 339\n",
      "Epoch= 340\n",
      "Epoch= 341\n",
      "Epoch= 342\n",
      "Epoch= 343\n",
      "Epoch= 344\n",
      "Epoch= 345\n",
      "Epoch= 346\n",
      "Epoch= 347\n",
      "Epoch= 348\n",
      "Epoch= 349\n",
      "Epoch= 350\n",
      "Epoch= 351\n",
      "Epoch= 352\n",
      "Epoch= 353\n",
      "Epoch= 354\n",
      "Epoch= 355\n",
      "Epoch= 356\n",
      "Epoch= 357\n",
      "Epoch= 358\n",
      "Epoch= 359\n",
      "Epoch= 360\n",
      "Epoch= 361\n",
      "Epoch= 362\n",
      "Epoch= 363\n",
      "Epoch= 364\n",
      "Epoch= 365\n",
      "Epoch= 366\n",
      "Epoch= 367\n",
      "Epoch= 368\n",
      "Epoch= 369\n",
      "Epoch= 370\n",
      "Epoch= 371\n",
      "Epoch= 372\n",
      "Epoch= 373\n",
      "Epoch= 374\n",
      "Epoch= 375\n",
      "Epoch= 376\n",
      "Epoch= 377\n",
      "Epoch= 378\n",
      "Epoch= 379\n",
      "Epoch= 380\n",
      "Epoch= 381\n",
      "Epoch= 382\n",
      "Epoch= 383\n",
      "Epoch= 384\n",
      "Epoch= 385\n",
      "Epoch= 386\n",
      "Epoch= 387\n",
      "Epoch= 388\n",
      "Epoch= 389\n",
      "Epoch= 390\n",
      "Epoch= 391\n",
      "Epoch= 392\n",
      "Epoch= 393\n",
      "Epoch= 394\n",
      "Epoch= 395\n",
      "Epoch= 396\n",
      "Epoch= 397\n",
      "Epoch= 398\n",
      "Epoch= 399\n",
      "Epoch= 400\n",
      "Epoch= 401\n",
      "Epoch= 402\n",
      "Epoch= 403\n",
      "Epoch= 404\n",
      "Epoch= 405\n",
      "Epoch= 406\n",
      "Epoch= 407\n",
      "Epoch= 408\n",
      "Epoch= 409\n",
      "Epoch= 410\n",
      "Epoch= 411\n",
      "Epoch= 412\n",
      "Epoch= 413\n",
      "Epoch= 414\n",
      "Epoch= 415\n",
      "Epoch= 416\n",
      "Epoch= 417\n",
      "Epoch= 418\n",
      "Epoch= 419\n",
      "Epoch= 420\n",
      "Epoch= 421\n",
      "Epoch= 422\n",
      "Epoch= 423\n",
      "Epoch= 424\n",
      "Epoch= 425\n",
      "Epoch= 426\n",
      "Epoch= 427\n",
      "Epoch= 428\n",
      "Epoch= 429\n",
      "Epoch= 430\n",
      "Epoch= 431\n",
      "Epoch= 432\n",
      "Epoch= 433\n",
      "Epoch= 434\n",
      "Epoch= 435\n",
      "Epoch= 436\n",
      "Epoch= 437\n",
      "Epoch= 438\n",
      "Epoch= 439\n",
      "Epoch= 440\n",
      "Epoch= 441\n",
      "Epoch= 442\n",
      "Epoch= 443\n",
      "Epoch= 444\n",
      "Epoch= 445\n",
      "Epoch= 446\n",
      "Epoch= 447\n",
      "Epoch= 448\n",
      "Epoch= 449\n",
      "Epoch= 450\n",
      "Epoch= 451\n",
      "Epoch= 452\n",
      "Epoch= 453\n",
      "Epoch= 454\n",
      "Epoch= 455\n",
      "Epoch= 456\n",
      "Epoch= 457\n",
      "Epoch= 458\n",
      "Epoch= 459\n",
      "Epoch= 460\n",
      "Epoch= 461\n",
      "Epoch= 462\n",
      "Epoch= 463\n",
      "Epoch= 464\n",
      "Epoch= 465\n",
      "Epoch= 466\n",
      "Epoch= 467\n",
      "Epoch= 468\n",
      "Epoch= 469\n",
      "Epoch= 470\n",
      "Epoch= 471\n",
      "Epoch= 472\n",
      "Epoch= 473\n",
      "Epoch= 474\n",
      "Epoch= 475\n",
      "Epoch= 476\n",
      "Epoch= 477\n",
      "Epoch= 478\n",
      "Epoch= 479\n",
      "Epoch= 480\n",
      "Epoch= 481\n",
      "Epoch= 482\n",
      "Epoch= 483\n",
      "Epoch= 484\n",
      "Epoch= 485\n",
      "Epoch= 486\n",
      "Epoch= 487\n",
      "Epoch= 488\n",
      "Epoch= 489\n",
      "Epoch= 490\n",
      "Epoch= 491\n",
      "Epoch= 492\n",
      "Epoch= 493\n",
      "Epoch= 494\n",
      "Epoch= 495\n",
      "Epoch= 496\n",
      "Epoch= 497\n",
      "Epoch= 498\n",
      "Epoch= 499\n",
      "Epoch= 500\n",
      "Epoch= 501\n",
      "Epoch= 502\n",
      "Epoch= 503\n",
      "Epoch= 504\n",
      "Epoch= 505\n",
      "Epoch= 506\n",
      "Epoch= 507\n",
      "Epoch= 508\n",
      "Epoch= 509\n",
      "Epoch= 510\n",
      "Epoch= 511\n",
      "Epoch= 512\n",
      "Epoch= 513\n",
      "Epoch= 514\n",
      "Epoch= 515\n",
      "Epoch= 516\n",
      "Epoch= 517\n",
      "Epoch= 518\n",
      "Epoch= 519\n",
      "Epoch= 520\n",
      "Epoch= 521\n",
      "Epoch= 522\n",
      "Epoch= 523\n",
      "Epoch= 524\n",
      "Epoch= 525\n",
      "Epoch= 526\n",
      "Epoch= 527\n",
      "Epoch= 528\n",
      "Epoch= 529\n",
      "Epoch= 530\n",
      "Epoch= 531\n",
      "Epoch= 532\n",
      "Epoch= 533\n",
      "Epoch= 534\n",
      "Epoch= 535\n",
      "Epoch= 536\n",
      "Epoch= 537\n",
      "Epoch= 538\n",
      "Epoch= 539\n",
      "Epoch= 540\n",
      "Epoch= 541\n",
      "Epoch= 542\n",
      "Epoch= 543\n",
      "Epoch= 544\n",
      "Epoch= 545\n",
      "Epoch= 546\n",
      "Epoch= 547\n",
      "Epoch= 548\n",
      "Epoch= 549\n",
      "Epoch= 550\n",
      "Epoch= 551\n",
      "Epoch= 552\n",
      "Epoch= 553\n",
      "Epoch= 554\n",
      "Epoch= 555\n",
      "Epoch= 556\n",
      "Epoch= 557\n",
      "Epoch= 558\n",
      "Epoch= 559\n",
      "Epoch= 560\n",
      "Epoch= 561\n",
      "Epoch= 562\n",
      "Epoch= 563\n",
      "Epoch= 564\n",
      "Epoch= 565\n",
      "Epoch= 566\n",
      "Epoch= 567\n",
      "Epoch= 568\n",
      "Epoch= 569\n",
      "Epoch= 570\n",
      "Epoch= 571\n",
      "Epoch= 572\n",
      "Epoch= 573\n",
      "Epoch= 574\n",
      "Epoch= 575\n",
      "Epoch= 576\n",
      "Epoch= 577\n",
      "Epoch= 578\n",
      "Epoch= 579\n",
      "Epoch= 580\n",
      "Epoch= 581\n",
      "Epoch= 582\n",
      "Epoch= 583\n",
      "Epoch= 584\n",
      "Epoch= 585\n",
      "Epoch= 586\n",
      "Epoch= 587\n",
      "Epoch= 588\n",
      "Epoch= 589\n",
      "Epoch= 590\n",
      "Epoch= 591\n",
      "Epoch= 592\n",
      "Epoch= 593\n",
      "Epoch= 594\n",
      "Epoch= 595\n",
      "Epoch= 596\n",
      "Epoch= 597\n",
      "Epoch= 598\n",
      "Epoch= 599\n",
      "Epoch= 600\n",
      "Epoch= 601\n",
      "Epoch= 602\n",
      "Epoch= 603\n",
      "Epoch= 604\n",
      "Epoch= 605\n",
      "Epoch= 606\n",
      "Epoch= 607\n",
      "Epoch= 608\n",
      "Epoch= 609\n",
      "Epoch= 610\n",
      "Epoch= 611\n",
      "Epoch= 612\n",
      "Epoch= 613\n",
      "Epoch= 614\n",
      "Epoch= 615\n",
      "Epoch= 616\n",
      "Epoch= 617\n",
      "Epoch= 618\n",
      "Epoch= 619\n",
      "Epoch= 620\n",
      "Epoch= 621\n",
      "Epoch= 622\n",
      "Epoch= 623\n",
      "Epoch= 624\n",
      "Epoch= 625\n",
      "Epoch= 626\n",
      "Epoch= 627\n",
      "Epoch= 628\n",
      "Epoch= 629\n",
      "Epoch= 630\n",
      "Epoch= 631\n",
      "Epoch= 632\n",
      "Epoch= 633\n",
      "Epoch= 634\n",
      "Epoch= 635\n",
      "Epoch= 636\n",
      "Epoch= 637\n",
      "Epoch= 638\n",
      "Epoch= 639\n",
      "Epoch= 640\n",
      "Epoch= 641\n",
      "Epoch= 642\n",
      "Epoch= 643\n",
      "Epoch= 644\n",
      "Epoch= 645\n",
      "Epoch= 646\n",
      "Epoch= 647\n",
      "Epoch= 648\n",
      "Epoch= 649\n",
      "Epoch= 650\n",
      "Epoch= 651\n",
      "Epoch= 652\n",
      "Epoch= 653\n",
      "Epoch= 654\n",
      "Epoch= 655\n",
      "Epoch= 656\n",
      "Epoch= 657\n",
      "Epoch= 658\n",
      "Epoch= 659\n",
      "Epoch= 660\n",
      "Epoch= 661\n",
      "Epoch= 662\n",
      "Epoch= 663\n",
      "Epoch= 664\n",
      "Epoch= 665\n",
      "Epoch= 666\n",
      "Epoch= 667\n",
      "Epoch= 668\n",
      "Epoch= 669\n",
      "Epoch= 670\n",
      "Epoch= 671\n",
      "Epoch= 672\n",
      "Epoch= 673\n",
      "Epoch= 674\n",
      "Epoch= 675\n",
      "Epoch= 676\n",
      "Epoch= 677\n",
      "Epoch= 678\n",
      "Epoch= 679\n",
      "Epoch= 680\n",
      "Epoch= 681\n",
      "Epoch= 682\n",
      "Epoch= 683\n",
      "Epoch= 684\n",
      "Epoch= 685\n",
      "Epoch= 686\n",
      "Epoch= 687\n",
      "Epoch= 688\n",
      "Epoch= 689\n",
      "Epoch= 690\n",
      "Epoch= 691\n",
      "Epoch= 692\n",
      "Epoch= 693\n",
      "Epoch= 694\n",
      "Epoch= 695\n",
      "Epoch= 696\n",
      "Epoch= 697\n",
      "Epoch= 698\n",
      "Epoch= 699\n",
      "Epoch= 700\n",
      "Epoch= 701\n",
      "Epoch= 702\n",
      "Epoch= 703\n",
      "Epoch= 704\n",
      "Epoch= 705\n",
      "Epoch= 706\n",
      "Epoch= 707\n",
      "Epoch= 708\n",
      "Epoch= 709\n",
      "Epoch= 710\n",
      "Epoch= 711\n",
      "Epoch= 712\n",
      "Epoch= 713\n",
      "Epoch= 714\n",
      "Epoch= 715\n",
      "Epoch= 716\n",
      "Epoch= 717\n",
      "Epoch= 718\n",
      "Epoch= 719\n",
      "Epoch= 720\n",
      "Epoch= 721\n",
      "Epoch= 722\n",
      "Epoch= 723\n",
      "Epoch= 724\n",
      "Epoch= 725\n",
      "Epoch= 726\n",
      "Epoch= 727\n",
      "Epoch= 728\n",
      "Epoch= 729\n",
      "Epoch= 730\n",
      "Epoch= 731\n",
      "Epoch= 732\n",
      "Epoch= 733\n",
      "Epoch= 734\n",
      "Epoch= 735\n",
      "Epoch= 736\n",
      "Epoch= 737\n",
      "Epoch= 738\n",
      "Epoch= 739\n",
      "Epoch= 740\n",
      "Epoch= 741\n",
      "Epoch= 742\n",
      "Epoch= 743\n",
      "Epoch= 744\n",
      "Epoch= 745\n",
      "Epoch= 746\n",
      "Epoch= 747\n",
      "Epoch= 748\n",
      "Epoch= 749\n",
      "Epoch= 750\n",
      "Epoch= 751\n",
      "Epoch= 752\n",
      "Epoch= 753\n",
      "Epoch= 754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 755\n",
      "Epoch= 756\n",
      "Epoch= 757\n",
      "Epoch= 758\n",
      "Epoch= 759\n",
      "Epoch= 760\n",
      "Epoch= 761\n",
      "Epoch= 762\n",
      "Epoch= 763\n",
      "Epoch= 764\n",
      "Epoch= 765\n",
      "Epoch= 766\n",
      "Epoch= 767\n",
      "Epoch= 768\n",
      "Epoch= 769\n",
      "Epoch= 770\n",
      "Epoch= 771\n",
      "Epoch= 772\n",
      "Epoch= 773\n",
      "Epoch= 774\n",
      "Epoch= 775\n",
      "Epoch= 776\n",
      "Epoch= 777\n",
      "Epoch= 778\n",
      "Epoch= 779\n",
      "Epoch= 780\n",
      "Epoch= 781\n",
      "Epoch= 782\n",
      "Epoch= 783\n",
      "Epoch= 784\n",
      "Epoch= 785\n",
      "Epoch= 786\n",
      "Epoch= 787\n",
      "Epoch= 788\n",
      "Epoch= 789\n",
      "Epoch= 790\n",
      "Epoch= 791\n",
      "Epoch= 792\n",
      "Epoch= 793\n",
      "Epoch= 794\n",
      "Epoch= 795\n",
      "Epoch= 796\n",
      "Epoch= 797\n",
      "Epoch= 798\n",
      "Epoch= 799\n",
      "Epoch= 800\n",
      "Epoch= 801\n",
      "Epoch= 802\n",
      "Epoch= 803\n",
      "Epoch= 804\n",
      "Epoch= 805\n",
      "Epoch= 806\n",
      "Epoch= 807\n",
      "Epoch= 808\n",
      "Epoch= 809\n",
      "Epoch= 810\n",
      "Epoch= 811\n",
      "Epoch= 812\n",
      "Epoch= 813\n",
      "Epoch= 814\n",
      "Epoch= 815\n",
      "Epoch= 816\n",
      "Epoch= 817\n",
      "Epoch= 818\n",
      "Epoch= 819\n",
      "Epoch= 820\n",
      "Epoch= 821\n",
      "Epoch= 822\n",
      "Epoch= 823\n",
      "Epoch= 824\n",
      "Epoch= 825\n",
      "Epoch= 826\n",
      "Epoch= 827\n",
      "Epoch= 828\n",
      "Epoch= 829\n",
      "Epoch= 830\n",
      "Epoch= 831\n",
      "Epoch= 832\n",
      "Epoch= 833\n",
      "Epoch= 834\n",
      "Epoch= 835\n",
      "Epoch= 836\n",
      "Epoch= 837\n",
      "Epoch= 838\n",
      "Epoch= 839\n",
      "Epoch= 840\n",
      "Epoch= 841\n",
      "Epoch= 842\n",
      "Epoch= 843\n",
      "Epoch= 844\n",
      "Epoch= 845\n",
      "Epoch= 846\n",
      "Epoch= 847\n",
      "Epoch= 848\n",
      "Epoch= 849\n",
      "Epoch= 850\n",
      "Epoch= 851\n",
      "Epoch= 852\n",
      "Epoch= 853\n",
      "Epoch= 854\n",
      "Epoch= 855\n",
      "Epoch= 856\n",
      "Epoch= 857\n",
      "Epoch= 858\n",
      "Epoch= 859\n",
      "Epoch= 860\n",
      "Epoch= 861\n",
      "Epoch= 862\n",
      "Epoch= 863\n",
      "Epoch= 864\n",
      "Epoch= 865\n",
      "Epoch= 866\n",
      "Epoch= 867\n",
      "Epoch= 868\n",
      "Epoch= 869\n",
      "Epoch= 870\n",
      "Epoch= 871\n",
      "Epoch= 872\n",
      "Epoch= 873\n",
      "Epoch= 874\n",
      "Epoch= 875\n",
      "Epoch= 876\n",
      "Epoch= 877\n",
      "Epoch= 878\n",
      "Epoch= 879\n",
      "Epoch= 880\n",
      "Epoch= 881\n",
      "Epoch= 882\n",
      "Epoch= 883\n",
      "Epoch= 884\n",
      "Epoch= 885\n",
      "Epoch= 886\n",
      "Epoch= 887\n",
      "Epoch= 888\n",
      "Epoch= 889\n",
      "Epoch= 890\n",
      "Epoch= 891\n",
      "Epoch= 892\n",
      "Epoch= 893\n",
      "Epoch= 894\n",
      "Epoch= 895\n",
      "Epoch= 896\n",
      "Epoch= 897\n",
      "Epoch= 898\n",
      "Epoch= 899\n",
      "Epoch= 900\n",
      "Epoch= 901\n",
      "Epoch= 902\n",
      "Epoch= 903\n",
      "Epoch= 904\n",
      "Epoch= 905\n",
      "Epoch= 906\n",
      "Epoch= 907\n",
      "Epoch= 908\n",
      "Epoch= 909\n",
      "Epoch= 910\n",
      "Epoch= 911\n",
      "Epoch= 912\n",
      "Epoch= 913\n",
      "Epoch= 914\n",
      "Epoch= 915\n",
      "Epoch= 916\n",
      "Epoch= 917\n",
      "Epoch= 918\n",
      "Epoch= 919\n",
      "Epoch= 920\n",
      "Epoch= 921\n",
      "Epoch= 922\n",
      "Epoch= 923\n",
      "Epoch= 924\n",
      "Epoch= 925\n",
      "Epoch= 926\n",
      "Epoch= 927\n",
      "Epoch= 928\n",
      "Epoch= 929\n",
      "Epoch= 930\n",
      "Epoch= 931\n",
      "Epoch= 932\n",
      "Epoch= 933\n",
      "Epoch= 934\n",
      "Epoch= 935\n",
      "Epoch= 936\n",
      "Epoch= 937\n",
      "Epoch= 938\n",
      "Epoch= 939\n",
      "Epoch= 940\n",
      "Epoch= 941\n",
      "Epoch= 942\n",
      "Epoch= 943\n",
      "Epoch= 944\n",
      "Epoch= 945\n",
      "Epoch= 946\n",
      "Epoch= 947\n",
      "Epoch= 948\n",
      "Epoch= 949\n",
      "Epoch= 950\n",
      "Epoch= 951\n",
      "Epoch= 952\n",
      "Epoch= 953\n",
      "Epoch= 954\n",
      "Epoch= 955\n",
      "Epoch= 956\n",
      "Epoch= 957\n",
      "Epoch= 958\n",
      "Epoch= 959\n",
      "Epoch= 960\n",
      "Epoch= 961\n",
      "Epoch= 962\n",
      "Epoch= 963\n",
      "Epoch= 964\n",
      "Epoch= 965\n",
      "Epoch= 966\n",
      "Epoch= 967\n",
      "Epoch= 968\n",
      "Epoch= 969\n",
      "Epoch= 970\n",
      "Epoch= 971\n",
      "Epoch= 972\n",
      "Epoch= 973\n",
      "Epoch= 974\n",
      "Epoch= 975\n",
      "Epoch= 976\n",
      "Epoch= 977\n",
      "Epoch= 978\n",
      "Epoch= 979\n",
      "Epoch= 980\n",
      "Epoch= 981\n",
      "Epoch= 982\n",
      "Epoch= 983\n",
      "Epoch= 984\n",
      "Epoch= 985\n",
      "Epoch= 986\n",
      "Epoch= 987\n",
      "Epoch= 988\n",
      "Epoch= 989\n",
      "Epoch= 990\n",
      "Epoch= 991\n",
      "Epoch= 992\n",
      "Epoch= 993\n",
      "Epoch= 994\n",
      "Epoch= 995\n",
      "Epoch= 996\n",
      "Epoch= 997\n",
      "Epoch= 998\n",
      "Epoch= 999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#print(\"n=\", n)\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_housing_data_plus_bias, housing.target)\n",
    "#    print(X_train.shape)\n",
    "#    print(y_train.shape)\n",
    "    return X_train, y_train.reshape(-1, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch=\", epoch)\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの保存と復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch= 0\n",
      "Epoch= 1\n",
      "Epoch= 2\n",
      "Epoch= 3\n",
      "Epoch= 4\n",
      "Epoch= 5\n",
      "Epoch= 6\n",
      "Epoch= 7\n",
      "Epoch= 8\n",
      "Epoch= 9\n",
      "best_theta: [[ 0.18321323]\n",
      " [ 0.8473657 ]\n",
      " [ 0.12728973]\n",
      " [-0.29153892]\n",
      " [ 0.32288796]\n",
      " [-0.0020721 ]\n",
      " [-0.03923169]\n",
      " [-0.8231216 ]\n",
      " [-0.7950508 ]]\n",
      "save_path: ./trained_model/my_model_finally.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model/my_model_finally.ckpt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver_theta = tf.train.Saver({\"weights\": theta})\n",
    "\n",
    "#print(\"n=\", n)\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_housing_data_plus_bias, housing.target)\n",
    "#    print(X_train.shape)\n",
    "#    print(y_train.shape)\n",
    "    return X_train, y_train.reshape(-1, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 10 == 0:\n",
    "            save_path = saver.save(sess, \"./trained_model/my_model.ckpt\")\n",
    "            save_theta_path = saver_theta.save(sess, \".trained_model/my_model_theta.ckpt\")\n",
    "            \n",
    "        print(\"Epoch=\", epoch)\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"./trained_model/my_model_finally.ckpt\")\n",
    "    save_theta_path = saver_theta.save(sess, \".trained_model/my_model_theta_finally.ckpt\")\n",
    "    print(\"best_theta:\", best_theta)\n",
    "    print(\"save_path:\", save_path)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./trained_model/my_model_finally.ckpt\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoardを使ったグラフと訓練曲線の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}\".format(root_logdir, now)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "scaled_housing_data_plus_bias = scaler.fit_transform(housing_data_plus_bias)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver_theta = tf.train.Saver({\"weights\": theta})\n",
    "\n",
    "mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_housing_data_plus_bias, housing.target)\n",
    "    \n",
    "    return X_train, y_train.reshape(-1, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 10 == 0:\n",
    "            save_path = saver.save(sess, \"./trained_model/my_model.ckpt\")\n",
    "            save_theta_path = saver_theta.save(sess, \".trained_model/my_model_theta.ckpt\")\n",
    "            \n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            \n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"./trained_model/my_model_finally.ckpt\")\n",
    "    save_theta_path = saver_theta.save(sess, \".trained_model/my_model_theta_finally.ckpt\")\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, \"./trained_model/my_model_finally.ckpt\")\n",
    "        \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
